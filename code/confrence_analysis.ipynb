{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f14ec13-ba32-4db9-8a50-857e5ce9de95",
   "metadata": {},
   "source": [
    "# GeoInt Conference  Analysis\n",
    "The purpose of this notebook is to explore the GeoInt 2024 website and to perform some basic analytics.\n",
    "\n",
    "The not book consists of several components:\n",
    "* Web scrapping\n",
    "* Data prep\n",
    "* Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bc1c13-9c63-4fd0-a5e7-dd57dbdda196",
   "metadata": {},
   "source": [
    "## Web Scrapping\n",
    "<p>Web scraping is a technique of extracting data from websites by simulating the behavior of a web browser. Web scraping can be useful for various purposes, such as market research, content analysis, or data journalism. However, web scraping also raises ethical and legal issues, especially regarding the privacy and copyright of the website owners and users. Therefore, it is important to follow the robots.txt file, which is a standard protocol that specifies which parts of a website can or cannot be scraped by automated agents.</p>\n",
    "\n",
    "<p>The robot file for GeoInt can be found here: <a href='https://geoint24.mapyourshow.com/robots.txt'>robot.txt</a></p>\n",
    "\n",
    "<p>Prior to GenAI web scraping required significantly more skill, time and external packages; however, now using language models you can either extract the data through prompting or have a language model write complex regex statements for you in seconds. The second method can have its advantages if you will be iterating over hundreds or thousands of pages sharing a standard format.</p>\r\n",
    "<p>\n",
    "Note: all scraping functionality in this notebook was create in whole or in part by various LLMs</p>.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c9f6b-4f6e-4ac7-93b9-809c8e55de93",
   "metadata": {},
   "source": [
    "### Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29b0ba07-6c2c-4414-9c4c-fe5e09d120c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def fetch_text(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return response.text    \n",
    "\n",
    "# extract the session title from the text using regex\n",
    "def extract_session_title(text):\n",
    "    pattern = r'<title>(.*?)<\\/title>'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def extract_speaker_name(html_content):\n",
    "    # Regex pattern to find content within <h1> tags with specific classes\n",
    "    pattern = r'<h1 class=\"[^\"]*\">\\s*([^\\n\\r<]+)\\s*</h1>'\n",
    "    # Search for the pattern in the HTML content\n",
    "    match = re.search(pattern, html_content)\n",
    "    # Return the matched group if found, otherwise return None\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def extract_job_title(html_content):\n",
    "    # Regex pattern to find content within <div> tags with specific classes that likely contain job titles\n",
    "    pattern = r'<div class=\"muted\\s+mb3\\s+f2\\s+lh-title\">\\s*([^<]+)\\s*</div>'\n",
    "    # Search for the pattern in the HTML content\n",
    "    match = re.search(pattern, html_content)\n",
    "    # Return the matched group if found, otherwise return None\n",
    "    if match:\n",
    "        speaker_title = match.group(1)\n",
    "        speaker_title = re.sub(r'\\s+', ' ', speaker_title)\n",
    "        \n",
    "        \n",
    "        return speaker_title\n",
    "    return None\n",
    "\n",
    "def extract_bio(html_content):\n",
    "    # Regex pattern to find content within <p> tags with the class \"o-DynamicContent text f5 lh-copy mb0\"\n",
    "    pattern = r'<p class=\"o-DynamicContent\\s+text\\s+f5\\s+lh-copy\\s+mb0\">\\s*([\\s\\S]*?)\\s*</p>'\n",
    "    # Search for the pattern in the HTML content\n",
    "    match = re.search(pattern, html_content)\n",
    "    # Return the matched group if found, otherwise return None\n",
    "    if match:\n",
    "        speaker_bio = match.group(1).strip()\n",
    "\n",
    "        # remove newline characters\n",
    "        speaker_bio = re.sub(r'\\s+', ' ', speaker_bio)\n",
    "\n",
    "\n",
    "        return speaker_bio\n",
    "    return \"Bio not found\"\n",
    "\n",
    "\n",
    "def extract_description(html_content):\n",
    "    # Regex pattern to find content within the 'content' attribute of a <meta> tag with the name 'description'\n",
    "    pattern = r'<meta name=\"description\" content=\"([^\"]+)\"\\s*/?>'\n",
    "    # Search for the pattern in the HTML content\n",
    "    match = re.search(pattern, html_content)\n",
    "    # Return the matched group if found, otherwise return None\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"Session description not found\"\n",
    "\n",
    "\n",
    "def extract_session_type(html_text):\n",
    "    # Regex pattern to find the session type following the specific structure\n",
    "    pattern = r'<span class=\"break-word\\s+lh-list\\s+muted\\s+pr2\\s+b\">Type:</span>\\s*<span class=\"break-word\\s+lh-list\">\\s*([^<]+)\\s*</span>'\n",
    "    match = re.search(pattern, html_text)\n",
    "    if match:\n",
    "        return match.group(1).strip()  # Return the captured session type, stripping any extra whitespace\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a304ef2-e15d-4229-8d4f-cbe8c03d7b86",
   "metadata": {},
   "source": [
    "### Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d16e776-62af-40a6-9d3c-de2bac40e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base urls\n",
    "session_base_url = 'https://geoint24.mapyourshow.com/8_0/sessions/session-details.cfm?scheduleid='\n",
    "speaker_base_url = 'https://geoint24.mapyourshow.com/8_0/sessions/speaker-details.cfm?speakerid='\n",
    "\n",
    "# Define the delay if needed and wait time (Following robot.txt)\n",
    "crawl_delay = 0\n",
    "\n",
    "# Set the maximum allowed failed attempts\n",
    "max_failed_attempts = 10\n",
    "max_attempts = 1000\n",
    "\n",
    "# Set the output path\n",
    "output_base_path = '../data/geoint/'\n",
    "\n",
    "# Check if a directory exists, if it does not exist, create it\n",
    "\n",
    "if not os.path.exists(output_base_path):\n",
    "    os.makedirs(output_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9069bf6-c4c0-41c1-892b-b1a60a839cfe",
   "metadata": {},
   "source": [
    "### Scrub Speaker Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc27e55-50dd-45c4-b030-ce130d113951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract data for speaker ID 6. Total failures: 1\n",
      "Failed to extract data for speaker ID 29. Total failures: 1\n",
      "Failed to extract data for speaker ID 34. Total failures: 1\n",
      "Failed to extract data for speaker ID 47. Total failures: 1\n",
      "Failed to extract data for speaker ID 50. Total failures: 1\n",
      "Failed to extract data for speaker ID 51. Total failures: 2\n",
      "Failed to extract data for speaker ID 54. Total failures: 1\n",
      "Failed to extract data for speaker ID 56. Total failures: 1\n",
      "Failed to extract data for speaker ID 59. Total failures: 1\n",
      "Failed to extract data for speaker ID 61. Total failures: 1\n",
      "Failed to extract data for speaker ID 62. Total failures: 2\n",
      "Failed to extract data for speaker ID 63. Total failures: 3\n",
      "Failed to extract data for speaker ID 64. Total failures: 4\n",
      "Failed to extract data for speaker ID 68. Total failures: 1\n",
      "Failed to extract data for speaker ID 70. Total failures: 1\n",
      "Failed to extract data for speaker ID 73. Total failures: 1\n",
      "Failed to extract data for speaker ID 75. Total failures: 1\n",
      "Failed to extract data for speaker ID 78. Total failures: 1\n",
      "Failed to extract data for speaker ID 89. Total failures: 1\n",
      "Failed to extract data for speaker ID 95. Total failures: 1\n",
      "Failed to extract data for speaker ID 127. Total failures: 1\n",
      "Failed to extract data for speaker ID 165. Total failures: 1\n",
      "Failed to extract data for speaker ID 166. Total failures: 2\n",
      "Failed to extract data for speaker ID 175. Total failures: 1\n",
      "Failed to extract data for speaker ID 193. Total failures: 1\n",
      "Failed to extract data for speaker ID 198. Total failures: 1\n",
      "Failed to extract data for speaker ID 201. Total failures: 1\n",
      "Failed to extract data for speaker ID 230. Total failures: 1\n",
      "Failed to extract data for speaker ID 233. Total failures: 1\n",
      "Failed to extract data for speaker ID 246. Total failures: 1\n",
      "Failed to extract data for speaker ID 247. Total failures: 2\n",
      "Failed to extract data for speaker ID 248. Total failures: 3\n",
      "Failed to extract data for speaker ID 249. Total failures: 4\n",
      "Failed to extract data for speaker ID 250. Total failures: 5\n",
      "Failed to extract data for speaker ID 251. Total failures: 6\n",
      "Failed to extract data for speaker ID 252. Total failures: 7\n",
      "Failed to extract data for speaker ID 253. Total failures: 8\n",
      "Failed to extract data for speaker ID 254. Total failures: 9\n",
      "Failed to extract data for speaker ID 255. Total failures: 10\n"
     ]
    }
   ],
   "source": [
    "speaker_names = []\n",
    "speaker_titles = []\n",
    "speaker_bios = []\n",
    "speaker_urls = []\n",
    "\n",
    "i = 1  # Start with the first speaker\n",
    "failed_attempts = 0\n",
    "while failed_attempts < max_failed_attempts:\n",
    "    url = speaker_base_url + str(i)\n",
    "\n",
    "    text = fetch_text(url)\n",
    "    \n",
    "    # Extract details\n",
    "    name = extract_speaker_name(text)\n",
    "    title = extract_job_title(text)\n",
    "    bio = extract_bio(text)\n",
    "\n",
    "    # Check for failures in extraction\n",
    "    if not title:\n",
    "        failed_attempts += 1\n",
    "        print(f\"Failed to extract data for speaker ID {i}. Total failures: {failed_attempts}\")\n",
    "    else:\n",
    "        failed_attempts = 0\n",
    "        \n",
    "        speaker_names.append(name)\n",
    "        speaker_titles.append(title)\n",
    "        speaker_bios.append(bio)\n",
    "        speaker_urls.append(url)\n",
    "\n",
    "    # used for debugging \n",
    "    #if i % 10 == 0:\n",
    "        #print(i)\n",
    "    \n",
    "    i += 1  # Move to the next speaker ID\n",
    "\n",
    "    if crawl_delay > 0:\n",
    "        time.sleep(crawl_delay)\n",
    "\n",
    "    # Optionally, you can add a break condition if you expect only a certain number of speakers\n",
    "    if i > max_attempts:\n",
    "         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0710a3e1-7990-4b36-9987-8c32450be690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Bio</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robert Cardillo</td>\n",
       "      <td>Chair, USGIF Board of Directors at USGIF</td>\n",
       "      <td>Robert Cardillo is the president of The Cardil...</td>\n",
       "      <td>https://geoint24.mapyourshow.com/8_0/sessions/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ronda Schrenk</td>\n",
       "      <td>Chief Executive Officer at USGIF</td>\n",
       "      <td>Ronda Schrenk is the Chief Executive Officer f...</td>\n",
       "      <td>https://geoint24.mapyourshow.com/8_0/sessions/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christy Monaco</td>\n",
       "      <td>Vice President of Programs at USGIF</td>\n",
       "      <td></td>\n",
       "      <td>https://geoint24.mapyourshow.com/8_0/sessions/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tara Mott</td>\n",
       "      <td>Account Manager at Esri</td>\n",
       "      <td></td>\n",
       "      <td>https://geoint24.mapyourshow.com/8_0/sessions/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jeff Dawley</td>\n",
       "      <td>Director of Intelligence Programs at Esri</td>\n",
       "      <td>Jeff Dawley currently serves as the Director o...</td>\n",
       "      <td>https://geoint24.mapyourshow.com/8_0/sessions/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name                                       Title  \\\n",
       "0  Robert Cardillo   Chair, USGIF Board of Directors at USGIF    \n",
       "1    Ronda Schrenk           Chief Executive Officer at USGIF    \n",
       "2   Christy Monaco        Vice President of Programs at USGIF    \n",
       "3        Tara Mott                    Account Manager at Esri    \n",
       "4      Jeff Dawley  Director of Intelligence Programs at Esri    \n",
       "\n",
       "                                                 Bio  \\\n",
       "0  Robert Cardillo is the president of The Cardil...   \n",
       "1  Ronda Schrenk is the Chief Executive Officer f...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Jeff Dawley currently serves as the Director o...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://geoint24.mapyourshow.com/8_0/sessions/...  \n",
       "1  https://geoint24.mapyourshow.com/8_0/sessions/...  \n",
       "2  https://geoint24.mapyourshow.com/8_0/sessions/...  \n",
       "3  https://geoint24.mapyourshow.com/8_0/sessions/...  \n",
       "4  https://geoint24.mapyourshow.com/8_0/sessions/...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframes with the extracted data\n",
    "df_speakers = pd.DataFrame({'Name': speaker_names, 'Title': speaker_titles, 'Bio': speaker_bios,'url': speaker_urls})\n",
    "\n",
    "# Clear variables\n",
    "#del speaker_names, speaker_titles, speaker_bios\n",
    "\n",
    "df_speakers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f1da1-9183-4301-81d0-cd95c9ee1364",
   "metadata": {},
   "source": [
    "### Scrap Session Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bafbc7d-a403-43b5-8634-d5bbeba670d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract data for session ID 4. Total failures: 1\n",
      "Failed to extract data for session ID 5. Total failures: 2\n",
      "10\n",
      "Failed to extract data for session ID 16. Total failures: 1\n",
      "Failed to extract data for session ID 17. Total failures: 2\n",
      "Failed to extract data for session ID 18. Total failures: 3\n",
      "20\n",
      "Failed to extract data for session ID 21. Total failures: 1\n",
      "Failed to extract data for session ID 22. Total failures: 2\n",
      "Failed to extract data for session ID 23. Total failures: 3\n",
      "Failed to extract data for session ID 26. Total failures: 1\n",
      "30\n",
      "40\n",
      "50\n",
      "Failed to extract data for session ID 59. Total failures: 1\n",
      "60\n",
      "70\n",
      "Failed to extract data for session ID 79. Total failures: 1\n",
      "80\n",
      "Failed to extract data for session ID 90. Total failures: 1\n",
      "90\n",
      "Failed to extract data for session ID 92. Total failures: 1\n",
      "100\n",
      "110\n",
      "Failed to extract data for session ID 117. Total failures: 1\n",
      "120\n",
      "Failed to extract data for session ID 128. Total failures: 1\n",
      "Failed to extract data for session ID 130. Total failures: 1\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "Failed to extract data for session ID 168. Total failures: 1\n",
      "Failed to extract data for session ID 169. Total failures: 2\n",
      "170\n",
      "Failed to extract data for session ID 176. Total failures: 1\n",
      "180\n",
      "Failed to extract data for session ID 181. Total failures: 1\n",
      "190\n",
      "200\n",
      "Failed to extract data for session ID 206. Total failures: 1\n",
      "Failed to extract data for session ID 207. Total failures: 2\n",
      "Failed to extract data for session ID 208. Total failures: 3\n",
      "Failed to extract data for session ID 209. Total failures: 4\n",
      "Failed to extract data for session ID 210. Total failures: 5\n",
      "210\n",
      "Failed to extract data for session ID 211. Total failures: 6\n",
      "Failed to extract data for session ID 212. Total failures: 7\n",
      "Failed to extract data for session ID 213. Total failures: 8\n",
      "Failed to extract data for session ID 214. Total failures: 9\n",
      "Failed to extract data for session ID 215. Total failures: 10\n"
     ]
    }
   ],
   "source": [
    "session_titles = []\n",
    "session_descriptions = []\n",
    "session_types = []\n",
    "session_urls = []\n",
    "\n",
    "i = 1  # Start with the first speaker\n",
    "failed_attempts = 0\n",
    "while failed_attempts < max_failed_attempts:\n",
    "    url = session_base_url + str(i)\n",
    "\n",
    "    text = fetch_text(url)\n",
    "    \n",
    "    # Extract details\n",
    "    title = extract_session_title(text)\n",
    "    description = extract_description(text)\n",
    "    type = extract_session_type(text)\n",
    "\n",
    "\n",
    "    # Check for failures in extraction\n",
    "    if not type:\n",
    "        failed_attempts += 1\n",
    "        print(f\"Failed to extract data for session ID {i}. Total failures: {failed_attempts}\")\n",
    "    else:\n",
    "        failed_attempts = 0\n",
    "        \n",
    "        session_titles.append(title)\n",
    "        session_descriptions.append(description)\n",
    "        session_types.append(type)\n",
    "        session_urls.append(url)\n",
    "\n",
    "    # used for debugging \n",
    "    #if i % 10 == 0:\n",
    "        #print(i)\n",
    "        \n",
    "    i += 1  # Move to the next speaker ID\n",
    "\n",
    "    if crawl_delay > 0:\n",
    "        time.sleep(crawl_delay)\n",
    "\n",
    "    # Optionally, you can add a break condition if you expect only a certain number of speakers\n",
    "    if i > max_attempts:\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d086a474-367c-4740-958f-7c0573ee0c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEOINT Foreword Welcome and Opening Remarks - ...</td>\n",
       "      <td>Join us as we kick off GEOINT Foreword with US...</td>\n",
       "      <td>Keynote Presentation</td>\n",
       "      <td>https://geoint24.mapyourshow.com/8_0/sessions/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keynote&amp;#x3a; Dare King, Chief Operating Offic...</td>\n",
       "      <td>Session description not found</td>\n",
       "      <td>Keynote Presentation</td>\n",
       "      <td>https://geoint24.mapyourshow.com/8_0/sessions/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Panel&amp;#x3a; Quantum Leap in Geospatial Intelli...</td>\n",
       "      <td>We’ll begin the day’s exploration of “Domain D...</td>\n",
       "      <td>Panel Discussion</td>\n",
       "      <td>https://geoint24.mapyourshow.com/8_0/sessions/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lunch &amp;amp; Student Poster Session - GEOINT 20...</td>\n",
       "      <td>Session description not found</td>\n",
       "      <td>Networking Events</td>\n",
       "      <td>https://geoint24.mapyourshow.com/8_0/sessions/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Panel&amp;#x3a; PNT Beyond GPS - GEOINT 2024 Sympo...</td>\n",
       "      <td>The advent of the Global Positioning System ha...</td>\n",
       "      <td>Panel Discussion</td>\n",
       "      <td>https://geoint24.mapyourshow.com/8_0/sessions/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  GEOINT Foreword Welcome and Opening Remarks - ...   \n",
       "1  Keynote&#x3a; Dare King, Chief Operating Offic...   \n",
       "2  Panel&#x3a; Quantum Leap in Geospatial Intelli...   \n",
       "3  Lunch &amp; Student Poster Session - GEOINT 20...   \n",
       "4  Panel&#x3a; PNT Beyond GPS - GEOINT 2024 Sympo...   \n",
       "\n",
       "                                         Description                  Type  \\\n",
       "0  Join us as we kick off GEOINT Foreword with US...  Keynote Presentation   \n",
       "1                      Session description not found  Keynote Presentation   \n",
       "2  We’ll begin the day’s exploration of “Domain D...      Panel Discussion   \n",
       "3                      Session description not found     Networking Events   \n",
       "4  The advent of the Global Positioning System ha...      Panel Discussion   \n",
       "\n",
       "                                                 url  \n",
       "0  https://geoint24.mapyourshow.com/8_0/sessions/...  \n",
       "1  https://geoint24.mapyourshow.com/8_0/sessions/...  \n",
       "2  https://geoint24.mapyourshow.com/8_0/sessions/...  \n",
       "3  https://geoint24.mapyourshow.com/8_0/sessions/...  \n",
       "4  https://geoint24.mapyourshow.com/8_0/sessions/...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframes with the extracted data\n",
    "session_df = pd.DataFrame({'Title': session_titles, 'Description': session_descriptions, 'Type': session_types,'url': session_urls})\n",
    "session_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "540ff1c1-f06c-45e0-b765-c41e9b0ef14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframes\n",
    "session_df.to_csv(output_base_path+'sessions.csv', index=False)\n",
    "df_speakers.to_csv(output_base_path+'speakers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ffaaa4-aef6-4d60-a9de-1e9adb310864",
   "metadata": {},
   "source": [
    "## Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f561eec-2b0b-4c36-86d9-98552900a7a1",
   "metadata": {},
   "source": [
    "### Imports and Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cec60231-eb53-439f-b9a1-33e3e404f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting wordcloud\n",
      "  Obtaining dependency information for wordcloud from https://files.pythonhosted.org/packages/90/be/1a7a488f5edcfae6746ffb91e792a1795b6cc058364ea6888b3878d3476f/wordcloud-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading wordcloud-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from wordcloud) (1.22.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from wordcloud) (3.7.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Downloading wordcloud-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.1/511.1 kB\u001b[0m \u001b[31m557.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8686e96-1112-4b10-9823-7208030e0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Create a list of word from the list of descriptions\n",
    "def extract_words(strings):\n",
    "    words = []\n",
    "    for string in strings:\n",
    "        words.extend(string.split())\n",
    "\n",
    "        # Remove non-alphabetic characters\n",
    "        words = [re.sub(r'\\W+', '', word) for word in words]\n",
    "\n",
    "        # Remove empty strings\n",
    "        words = [word for word in words if word]\n",
    "\n",
    "        # Convert all words to lowercase\n",
    "        words = [word.lower() for word in words]\n",
    "\n",
    "    return words\n",
    "\n",
    "def visualize_word_cloud(words):\n",
    "    # Join all the strings in the list to a single string\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    # Create a word cloud object\n",
    "    wordcloud = WordCloud(width=1200, height=800, background_color='white').generate(text)\n",
    "    \n",
    "    # Display the word cloud using matplotlib\n",
    "    plt.figure(figsize=(30, 15))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')  # Hide the axes\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c1e0e-1fbe-4d61-8991-776717801348",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0915a48-1a90-41c4-b6de-44fe8844206e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The _imagingft C module is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m words \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m removal_words]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mvisualize_word_cloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 25\u001b[0m, in \u001b[0;36mvisualize_word_cloud\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m     22\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(words)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Create a word cloud object\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Display the word cloud using matplotlib\u001b[39;00m\n\u001b[1;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m15\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:642\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    628\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    629\u001b[0m \n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:624\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \n\u001b[1;32m    609\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[0;32m--> 624\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    451\u001b[0m     font_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 453\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfrequencies\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# find font sizes\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout_]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:506\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# try to find a position\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m font \u001b[38;5;241m=\u001b[39m \u001b[43mImageFont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruetype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfont_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# transpose font optionally\u001b[39;00m\n\u001b[1;32m    508\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[1;32m    509\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFont.py:959\u001b[0m, in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfreetype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_path(font):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFont.py:956\u001b[0m, in \u001b[0;36mtruetype.<locals>.freetype\u001b[0;34m(font)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfreetype\u001b[39m(font):\n\u001b[0;32m--> 956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFreeTypeFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFont.py:219\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__\u001b[0;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layout_engine \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (Layout\u001b[38;5;241m.\u001b[39mBASIC, Layout\u001b[38;5;241m.\u001b[39mRAQM):\n\u001b[1;32m    218\u001b[0m     layout_engine \u001b[38;5;241m=\u001b[39m Layout\u001b[38;5;241m.\u001b[39mBASIC\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHAVE_RAQM\u001b[49m:\n\u001b[1;32m    220\u001b[0m         layout_engine \u001b[38;5;241m=\u001b[39m Layout\u001b[38;5;241m.\u001b[39mRAQM\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layout_engine \u001b[38;5;241m==\u001b[39m Layout\u001b[38;5;241m.\u001b[39mRAQM \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39mHAVE_RAQM:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFont.py:58\u001b[0m, in \u001b[0;36m_ImagingFtNotInstalled.__getattr__\u001b[0;34m(self, id)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mid\u001b[39m):\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imagingft C module is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: The _imagingft C module is not installed"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "words = extract_words(session_df.Description)\n",
    "\n",
    "removal_words = ['session','sessions','description','geoint','will','show','talk','presentation','attendees','attendee','attend','event',\n",
    "                 'discuss','discussions','discussing','discussed','discusses','discussant','discussants','discussing','discus','discussed'\n",
    "                 'lightning']\n",
    "\n",
    "# Remove the words in the removal_words list from the words list\n",
    "words = [word for word in words if word not in removal_words]\n",
    "\n",
    "# Example usage:\n",
    "visualize_word_cloud(words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
